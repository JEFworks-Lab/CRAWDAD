---
title: "2_spleen"
author: "Brendan F. Miller"
date: "2/15/2023"
output: html_document
---

```{r}

repoPath <- "/Users/brendan/Desktop/PostDoc/work/HuBMAP/repos/multiscale_celltype_colocalization_analysis/"

```

```{r}

library(parallel)
library(sf)
library(sp)
library(ggplot2)
library(assertthat)
library(reshape2)
library(MASS)
library(stats)
library(dplyr)

source(paste0(repoPath, "R/functions.R"))

```

# visualize clusters

select spleen dataset and the annotated clusters to use

```{r}

spleen <- "pkhl"
## other spleen datasets:
## pkhl xxcd ngpl ksfb pbvn fsld
## note: pairwise xxcd, ngpl, fsld seemed to have memory issues but were generated
## but the subsets were no problem, likely because each subset had a lot less cells

cluster <- "celltypes_folBcombined" ## Fol B ctr and outer clusters combined
## cluster columns:
## celltypes celltypes_folBcombined

```

```{r}

path_to_spleen <- paste0(repoPath, "data/spleen/", toupper(spleen), ".meta.csv.gz")

meta <- read.csv2(file = path_to_spleen, row.names = 1)
meta <- meta[,c("x", "y", cluster)]
## make sure the coordinates are numeric
meta <- meta %>% 
  dplyr::mutate_at(vars(x, y), as.numeric)

## change y coordinates to all positive
meta$y <- meta$y * -1

head(meta)

```

```{r, fig.height=24, fig.width=24}

vizEachCluster(object = meta[,c("x", "y")], clusters = as.factor(meta[,3]), s = 2)

```

# find pairwise trends

input files and parameters for `findTrends()`

```{r}

## full path to the shuffled data rds
## if it exists, it will be loaded into the function, if not, will be created and saved at this location
## example: "data/spleen/PKHL/pkhl.pairwise.100-200.folBcombined.results.res100-6000.removeDups.rds"

shuffledDataPath <- paste0(repoPath, "data/spleen/", toupper(spleen), "/", spleen,  ".folBcombined.shuffled_res100-6000.rds")
outfile <- paste0(repoPath, "data/spleen/", toupper(spleen), "/", spleen,  ".pairwise.100-200.folBcombined.results.res100-6000.removeDups.rds")

## number of cores
ncs <- 7 

## number of permutations
prms <- 1 

## seed
sd <- 1 

## don't count neighbor cells more than once
removedups <- TRUE

## for pairwise, can assess as several different neighbor distances, which will be combined at the end
distances <- c(100,200)
## shuffling resolutions
resolutions <- c(100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1500, 3000, 6000)

## the `pos` data.frame, but these lines load it back in properly
meta <- read.csv2(file = path_to_spleen, row.names = 1)
meta <- meta[,c("x", "y", cluster)]
## make sure the coordinates are numeric
meta <- meta %>% 
  dplyr::mutate_at(vars(x, y), as.numeric)

## change y coordinates to all positive
meta$y <- meta$y * -1

head(meta)

```

```{r}

pairwise_results <- lapply(distances, function(d){
  
  if(file.exists(shuffledDataPath)){
    
    results <- findTrendsv2(pos = meta[,c("x", "y")],
                             celltypes = meta[,3],
                             resolutions,
                             dist = d,
                             sub.type = "pairwise",
                             perms = prms,
                             ncores = ncs,
                             verbose = TRUE,
                             loadShuffleFile = shuffledDataPath,
                             seed = sd,
                             removeDups = removedups)
  } else {
    results <- findTrendsv2(pos = meta[,c("x", "y")],
                             celltypes = meta[,3],
                             resolutions,
                             dist = d,
                             sub.type = "pairwise",
                             perms = prms,
                             ncores = ncs,
                             verbose = TRUE,
                             saveShuffleFilePath = shuffledDataPath,
                             seed = sd,
                             removeDups = removedups)
  }
  # print(results)
  return(results)
  
})

names(pairwise_results) <- distances

saveRDS(object = pairwise_results, file = outfile)

```

notes when running on RockFish cluster:
1 node
14 CPUs
8G per CPU

PKHL

100 micron resolution
8645 tiles to shuffle...
shuffling permutation 1 using seed 1
200 micron resolution
2208 tiles to shuffle...
shuffling permutation 1 using seed 1
300 micron resolution
992 tiles to shuffle...
shuffling permutation 1 using seed 1
500 micron resolution
361 tiles to shuffle...
shuffling permutation 1 using seed 1
600 micron resolution
256 tiles to shuffle...
shuffling permutation 1 using seed 1
700 micron resolution
182 tiles to shuffle...
shuffling permutation 1 using seed 1
800 micron resolution
144 tiles to shuffle...
shuffling permutation 1 using seed 1
900 micron resolution
121 tiles to shuffle...
shuffling permutation 1 using seed 1
1000 micron resolution
100 tiles to shuffle...
shuffling permutation 1 using seed 1
1200 micron resolution
64 tiles to shuffle...
shuffling permutation 1 using seed 1
1500 micron resolution
49 tiles to shuffle...
shuffling permutation 1 using seed 1
3000 micron resolution
16 tiles to shuffle...
6000 micron resolution
4 tiles to shuffle

Just a few minutes to shuffle

using neighbor distance of 100
Calculating for pairwise combinations
B cells, red pulp
Blood endothelial
CD4 Memory T cells
CD8 Memory T cells
Fol B cells
indistinct
Ki67 proliferating
Macrophages
Myeloid cells
Neutrophils/Monocytes
Podoplanin
Sinusoidal cells
Time was 5.18 mins
Warning: `celltypes` does not have levels. Creating levels from values
creating `sp::SpatialPointsDataFrame`
Generate randomly permuted background at each resolution
Evaluating significance for each cell type
using neighbor distance of 200
Calculating for pairwise combinations
B cells, red pulp
Blood endothelial
CD4 Memory T cells
CD8 Memory T cells
Fol B cells
indistinct
Ki67 proliferating
Macrophages
Myeloid cells
Neutrophils/Monocytes
Podoplanin
Sinusoidal cells
Time was 19.46 mins


For the pairwise trends portion (distances 100-200)
seff:
Nodes: 1
Cores per node: 14
CPU Utilized: 03:18:52
CPU Efficiency: 57.55% of 05:45:34 core-walltime
Job Wall-clock time: 00:24:41
Memory Utilized: 96.49 GB
Memory Efficiency: 86.15% of 112.00 GB

now its about 150K cells
Other spleens similar memory and time


## visualize

```{r}

figPath <- paste0(repoPath, "plots/spleen/")

```

```{r}

dat <- readRDS(outfile)

dat <- meltResultsList(resultsList = dat, id = NA)
colnames(dat) <- c("resolution", "neighbor", "Z", "reference", "dist", "id")

head(dat)

```

```{r}

## visualize the trends with neighbor distance of 100
d <- dat[dat$dist == "100",]
plotTrends(results = d, idcol = "dist", legend = FALSE,
           figPath = paste0(figPath, spleen, ".pairwise.d100.trends.pdf"),
           width = 50, height = 50)

```

# find subset trends

## define the cell type subsets

input files and parameters for `getSubsets()`

```{r}

## full path to the subset dataset list rds
subsetDataPath <- paste0(repoPath, "data/spleen/", toupper(spleen), "/", spleen, ".subsets.near.subdist100.rds")

## test if a cell is "near" or "away" a given cell type
## by testing if it's neighbors are significantly enriched or depleted in a cell type via binomial test
subsetType <- "near"

## distance to define subsets; ie the distance to define neighbors for this test
subdist <- 100


## for "away", loosely test for enrichment, then take the cells that still fail this test
## so assume that they must be highly depleted
if(subsetType == "near"){
  subThresh <- 0.05
} else if(subsetType == "away"){
  subThresh <- 0.5
} else (
  stop("subsetType must be either 'near' or 'away'")
)

## number of cores
ncs <- 7 

## the `pos` data.frame, but these lines load it back in properly
meta <- read.csv2(file = path_to_spleen, row.names = 1)
meta <- meta[,c("x", "y", cluster)]
## make sure the coordinates are numeric
meta <- meta %>% 
  dplyr::mutate_at(vars(x, y), as.numeric)

## change y coordinates to all positive
meta$y <- meta$y * -1


## create the spatial dataframe:
pos <- meta[,c("x", "y")]
celltypes <- meta[,3]

if(length(levels(celltypes)) == 0){
  message("Warning: `celltypes` does not have levels. Creating levels from values")
  celltypes <- factor(celltypes)
  names(celltypes) <- rownames(pos)
}

cells <- sp::SpatialPointsDataFrame(
    coords = as.data.frame(pos),
    data = data.frame(
        celltypes = celltypes
        #name=rownames(pos)
))
cells <- sf::st_as_sf(cells)

## Change rowname assignments of cells to integers.
## Solution to keep rows in same order later on when
## randomly shuffling cell labels
rownames(cells) <- as.character(1:dim(cells)[1])

# make assumption that cell type attribute is constant throughout the geometries of each cell
## it removed the warning that keep popping up, which says this assumption is made anyways
sf::st_agr(cells) <- "constant"

```

```{r}

## if subset data exists, set up parameters to load it in, otherwise set them up to save it once made
if(file.exists(subsetDataPath)){
  loadSubset <- subsetDataPath
  saveSubset <- NA
} else {
  loadSubset <- NA
  saveSubset <- subsetDataPath
}

if(assertthat::is.string(loadSubset)){
    subset.list <- readRDS(file = loadSubset)
} else {
    
    ## parallel shuffling of the grids in each resolution
    subset.list <- getSubsets(cells = cells,
                            sub.dist = subdist,
                            sub.type = subsetType,
                            sub.thresh = subThresh,
                            ncores = ncs,
                            verbose = TRUE,
                            removeDups = FALSE)
    if(assertthat::is.string(saveSubset)){
        saveRDS(object = subset.list, file = saveSubset)
    }
}

```

notes from RockFish:
Identifying subsets of cells that are near a given neighbor cell type based on distance of 100

Warning - for spleens, generating subsets with 32 cores takes almost 1000 minutes
Time to compute was 909.64mins (PKHL)
for subset neighbor distance of 100

Neutrophils_near_Sinusoidal cells was about 20 minutes
31731 cells to test and 23396 potential neighbors

longest combination:
computing subsets for Granule_near_Granule
Time to compute was 0.18mins

seff:
Nodes: 1
Cores per node: 32
CPU Utilized: 12-23:36:31
CPU Efficiency: 64.22% of 20-05:13:36 core-walltime
Job Wall-clock time: 15:09:48
Memory Utilized: 17.87 GB
Memory Efficiency: 27.92% of 64.00 GB

Memory not too bad, but huge time sink

about 150K cells in PKHL
12 cell types, so 144 subset combos

B cells, red pulp     Blood endothelial    CD4 Memory T cells 
                 3322                  6201                  8790 
   CD8 Memory T cells           Fol B cells            indistinct 
                15977                 19550                 12141 
   Ki67 proliferating           Macrophages         Myeloid cells 
                 7824                 15916                  8860 
Neutrophils/Monocytes            Podoplanin      Sinusoidal cells 
                31731                   738                 23396 


## visualize subsets

```{r}

subsets <- readRDS(subsetDataPath)

id <- "subset dist 100"
pos <- meta[,c("x", "y")]
com <- as.factor(meta[,3])
names(com) <- rownames(pos)


# ----------------------------------------

annots_temp <- selectLabels(com = com,
                             pos = pos,
                             subset_list = subsets,
                             cellIDs = c("CD4 Memory T cells", "Podoplanin", "Fol B cells"),
                             subsetIDs = NA)
plt <- vizAllClusters(object = pos,
               clusters = annots_temp,
               title = id,
               axisAdj = 1, s = 4, a = 0.5) +
  ggplot2::guides(colour = ggplot2::guide_legend(override.aes = list(size=2), ncol = 1)) +
  # ggplot2::theme(legend.position="none") +
  ggplot2::labs(x = "x",
                y = "y")
plt

# ggplot2::ggsave(filename ="sim_circSubset.v2.AnearB.pdf",
#                 path = figpath, device = "pdf",
#                 plot = plt,
#                 dpi = 600, width = 4, height = 3, units = "in")

```

## subset trends

note that we can reuse the same shuffled dataset that was made in the pairwise analysis

```{r}

## full path to the shuffled data rds
## if it exists, it will be loaded into the function, if not, will be created and saved at this location
shuffledDataPath <- paste0(repoPath, "data/spleen/", toupper(spleen), "/", spleen,  ".folBcombined.shuffled_res100-6000.rds")
outfile_subsets_triplet <- paste0(repoPath, "data/spleen/", toupper(spleen), "/", spleen, ".triplet.near.binom.subdist100.dist100.folBcombined.results.res100-6000.removeDups.rds")

## full path to the subset dataset list rds
subsetDataPath <- paste0(repoPath, "data/spleen/", toupper(spleen), "/", spleen, ".subsets.near.subdist100.rds")

## test if a cell is "near" or "away" a given cell type
## by testing if it's neighbors are significantly enriched or depleted in a cell type via binomial test
subsetType <- "near"

## distance to define subsets; ie the distance to define neighbors for this test
subdist <- 100


## for "away", loosely test for enrichment, then take the cells that still fail this test
## so assume that they must be highly depleted
if(subsetType == "near"){
  subThresh <- 0.05
} else if(subsetType == "away"){
  subThresh <- 0.5
} else (
  stop("subsetType must be either 'near' or 'away'")
)


## number of cores
ncs <- 7 

## number of permutations
prms <- 1 

## seed
sd <- 1 

## don't count neighbor cells more than once
removedups <- TRUE

## for subset, use one neighbor distance
distances <- c(100)
## shuffling resolutions
resolutions <- c(100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1500, 3000, 6000)

## the `pos` data.frame, but these lines load it back in properly
meta <- read.csv2(file = path_to_spleen, row.names = 1)
meta <- meta[,c("x", "y", cluster)]
## make sure the coordinates are numeric
meta <- meta %>% 
  dplyr::mutate_at(vars(x, y), as.numeric)

## change y coordinates to all positive
meta$y <- meta$y * -1

head(meta)

```

```{r}

## if subset data exists, set up parameters to load it in, otherwise set them up to save it once made
if(file.exists(subsetDataPath)){
  loadSubset <- subsetDataPath
  saveSubset <- NA
} else {
  loadSubset <- NA
  saveSubset <- subsetDataPath
}

triplet_results <- lapply(distances, function(d){
  
  if(file.exists(shuffledDataPath)){
    
    results <- findTrendsv2(pos = meta[,c("x", "y")],
                             celltypes = meta[,3],
                             resolutions,
                             dist = d,
                             sub.dist = subdist,
                             sub.type = subsetType,
                             sub.thresh = subThresh,
                             perms = prms,
                             ncores = ncs,
                             verbose = TRUE,
                             loadShuffleFile = shuffledDataPath,
                             loadSubsetFile = loadSubset,
                             saveSubsetFile = saveSubset,
                             seed = sd,
                             removeDups = removedups)
  } else {
    results <- findTrendsv2(pos = meta[,c("x", "y")],
                             celltypes = meta[,3],
                             resolutions,
                             dist = d,
                             sub.dist = subdist,
                             sub.type = subsetType,
                             sub.thresh = subThresh,
                             perms = prms,
                             ncores = ncs,
                             verbose = TRUE,
                             saveShuffleFilePath = shuffledDataPath,
                             loadSubsetFile = loadSubset,
                             saveSubsetFile = saveSubset,
                             seed = sd,
                             removeDups = removedups)
  }
  return(results)
  
})

names(triplet_results) <- distances

saveRDS(object = triplet_results, file = outfile_subsets_triplet)

```

notes when running on RockFish cluster:
1 node
14 CPUs
8G per CPU (overkill for this)

seff:
Nodes: 1
Cores per node: 14
CPU Utilized: 01:31:57
CPU Efficiency: 53.04% of 02:53:22 core-walltime
Job Wall-clock time: 00:12:23
Memory Utilized: 18.82 GB
Memory Efficiency: 16.80% of 112.00 GB

running the triplets are much more manageable. Memory and speedwise
But making the subsets initially does take a long time, even if it isnt a memory sink

## visualize subset trends

```{r}

figPath <- paste0(repoPath, "plots/spleen/")

```

```{r}

dat <- readRDS(outfile_subsets_triplet)

dat <- meltResultsList(resultsList = dat, id = NA)
colnames(dat) <- c("resolution", "neighbor", "Z", "reference", "dist", "subdist")

dat$subdist = "100"

head(dat)

```

```{r}

## visualize the trends with neighbor distance of 100
d <- dat[dat$dist == "100",]

## too many subset cell combinations (144 x 144)
## so pick some of interest to visualize
d <- d[grepl(pattern = "Podoplanin_near", x = d$reference), ]


plotTrends(results = d, idcol = "dist", legend = FALSE,
           figPath = paste0(figPath, spleen, ".podo_subs.d100.sd100.trends.pdf"),
           width = 40, height = 40)

```







